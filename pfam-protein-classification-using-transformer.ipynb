{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## apply a transformer to classify protein families based on amino acid sequence\n\n## read in kaggle dataset using their API\n## this notebook is run within kaggle with filepaths pointing to data once it has been loaded\n## into the kernel session. Change /kaggle/input/pfam-seed-random-split/ to your current directory\n## requires Tensorflow version >2.2.0\n## !kaggle datasets download -d googleai/pfam-seed-random-split\n\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport math\nimport glob\n\ndef convertToNumber (s):\n    return int.from_bytes(s.encode(), 'little')\n\ndef convertFromNumber (n):\n    return n.to_bytes(math.ceil(n.bit_length() / 8), 'little').decode()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-26T10:58:24.227735Z","iopub.execute_input":"2022-02-26T10:58:24.228278Z","iopub.status.idle":"2022-02-26T10:58:30.687928Z","shell.execute_reply.started":"2022-02-26T10:58:24.228161Z","shell.execute_reply":"2022-02-26T10:58:30.687010Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"## read in training data\n## tokenize protein sequences and family membership\ndef ReadInData (path):\n    listprto=[]\n    listfam=[]\n    for file in glob.glob(path):\n        df=pd.read_csv(file, sep=',',header=None)\n        df = df.iloc[1: , :]\n        listprto1 = list(df.iloc[:, 4])\n        listprto = listprto + listprto1\n        listfam = listfam + list(df.iloc[:,0])\n    x_train = []\n    for listval in listprto:\n        x_train.append([ord(x) - 65 for x in listval])\n    y_train = [convertToNumber(item) for item in listfam]\n    return x_train , y_train\n\nx_train , y_train = ReadInData(\"/kaggle/input/pfam-seed-random-split/random_split/train/data-*\")\nx_test , y_test = ReadInData(\"/kaggle/input/pfam-seed-random-split/random_split/dev/data-*\")","metadata":{"execution":{"iopub.status.busy":"2022-02-26T11:01:26.809821Z","iopub.execute_input":"2022-02-26T11:01:26.810826Z","iopub.status.idle":"2022-02-26T11:02:06.056899Z","shell.execute_reply.started":"2022-02-26T11:01:26.810779Z","shell.execute_reply":"2022-02-26T11:02:06.055861Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"## custom layer for transformer block\nclass TransformerBlock(layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock, self).__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T11:06:54.481677Z","iopub.execute_input":"2022-02-26T11:06:54.482027Z","iopub.status.idle":"2022-02-26T11:06:54.495230Z","shell.execute_reply.started":"2022-02-26T11:06:54.481994Z","shell.execute_reply":"2022-02-26T11:06:54.493697Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"## prepare data for tensorflow and set parameters for number of tokens (number of proteins)\n## and for number of positions of the protein to consider\nvocab_size = 30\n## maxlen = max([len(item) for item in x_train])\nmaxlen = 25\n\nx_traink = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\nx_valk = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n\nkeys_list = list(set(y_train + y_test))\nvalues_list = range(len(keys_list))\nzip_iterator = zip(keys_list, values_list)\na_dictionary = dict(zip_iterator)\n\nC = (pd.Series(y_train)).map(a_dictionary)\nY_train = list(C)\n\nC1 = (pd.Series(y_test)).map(a_dictionary)\nY_test = list(C1)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T11:13:58.819387Z","iopub.execute_input":"2022-02-26T11:13:58.820246Z","iopub.status.idle":"2022-02-26T11:14:07.835210Z","shell.execute_reply.started":"2022-02-26T11:13:58.820203Z","shell.execute_reply":"2022-02-26T11:14:07.834400Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"## create embedding layer for amino acid and amino acid position \n\nclass TokenAndPositionEmbedding(layers.Layer):\n    def __init__(self, maxlen, vocab_size, embed_dim):\n        super(TokenAndPositionEmbedding, self).__init__()\n        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        x = self.token_emb(x)\n        return x + positions","metadata":{"execution":{"iopub.status.busy":"2022-02-26T11:14:07.836671Z","iopub.execute_input":"2022-02-26T11:14:07.837072Z","iopub.status.idle":"2022-02-26T11:14:07.843768Z","shell.execute_reply.started":"2022-02-26T11:14:07.837019Z","shell.execute_reply":"2022-02-26T11:14:07.842913Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"## set hyperparameters and create model\n\nembed_dim = 100  # embedding dimensions for each amino acid\nnum_heads = 8  # number of attention heads\nff_dim = 100  # hidden layer size in feed forward network inside transformer\n\ninputs = layers.Input(shape=(maxlen,))\nembedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\nx = embedding_layer(inputs)\ntransformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\nx = transformer_block(x)\nx = layers.GlobalAveragePooling1D()(x)\nx = layers.Dropout(0.1)(x)\nx = layers.Dense(100, activation=\"relu\")(x)\nx = layers.Dropout(0.1)(x)\noutputs = layers.Dense(len(a_dictionary), activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T11:14:17.339711Z","iopub.execute_input":"2022-02-26T11:14:17.340007Z","iopub.status.idle":"2022-02-26T11:14:17.528953Z","shell.execute_reply.started":"2022-02-26T11:14:17.339975Z","shell.execute_reply":"2022-02-26T11:14:17.528300Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"## compile and train model\nmodel.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\nhistory = model.fit(\n    x_traink, np.asarray(Y_train).astype('float32'), batch_size=512, epochs=3, validation_data=(x_valk, np.asarray(Y_test).astype('float32'))\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T11:14:20.189728Z","iopub.execute_input":"2022-02-26T11:14:20.190038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## prepare test data\nx_finaltest , y_finaltest = ReadInData(\"/kaggle/input/pfam-seed-random-split/random_split/test/data-*\")\nC1 = (pd.Series(y_finaltest)).map(a_dictionary)\nY_final = list(C1)\n\nx_finalk = keras.preprocessing.sequence.pad_sequences(x_finaltest, maxlen=100)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:46:06.916746Z","iopub.execute_input":"2022-02-23T19:46:06.917402Z","iopub.status.idle":"2022-02-23T19:46:11.209599Z","shell.execute_reply.started":"2022-02-23T19:46:06.917347Z","shell.execute_reply":"2022-02-23T19:46:11.208485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predict protein family from test set\npredicted_fin = model.predict(x_finalk)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## calculate accuracy\nsum(np.argmax(predicted_fin, axis=1) == Y_final)/len(Y_final)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## make table with test prediction, true value, and whether they match \nfinal = [np.argmax(predicted_fin, axis=1), Y_final, np.argmax(predicted_fin, axis=1) == Y_final]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## for each protein family calculate accuracy and total number of test sample\ncompare = [list(pd.DataFrame(final).T.groupby(1).mean().iloc[:,1]) , list(pd.DataFrame(final).T.groupby(1).size())]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}